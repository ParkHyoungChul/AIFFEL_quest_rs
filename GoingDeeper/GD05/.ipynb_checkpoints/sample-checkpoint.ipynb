{
 "cells": [
  {
   "attachments": {
    "image-2.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAo4AAAD0CAYAAAAVKKduAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAEHHSURBVHhe7d0JnE31/8fxj30f+04oEVpQqVAoUVnjl6JCe7/2xT8tKqWd0qI92kilRamkRCqFshTJ0s+SLWXf17n/eX2dw5k7d8adMXNn5no/H49rzPeeuffs53M+3+XkCSUxEREREZGDyOv9FBERERFJkwJHEREREYmKAkcRERERiYoCRxERERGJigJHEREREYmKAkcRERERiYoCRxERERGJigJHEREREYmKAkcRERERiYoCRxERERGJigJHEREREYmKAkcREZEcYsmSJfbSSy/Zpk2bvJL4N3bsWHvqqads1apVXkl8SkxMtG+++cYefvhhryR3UuAoIiISA//8848988wz1q5dOzv11FPdT37fuHGjN4VZyZIl7aOPPrKbb77ZBRrRuOOOO6xhw4bu1ahRIzvjjDOse/fu9vTTT+eKYGzMmDH2yCOP2IoVK7ySzLdy5cr962jy5MleaUobNmywrl27uumYp927d3vvHDq255dffmn9+vXzSnInBY4iIiJZbP369dayZUt74oknbMeOHXb00UfbunXr7N5773VB3urVq910pUuXtrvuuss+/vhj+/DDD13ZwSxdutTmz59vxx57rJ122mlWrVo1W7RokT3++OPuewYMGJAsOD0c7dq1y3799VebM2eODR061EKhkPdOcr/88osLLJlu+fLlqU53OFPgKCIiksXINrVt29a++uorV1359ttv27fffmuPPvqo+zl+/HhvSnMB5llnneWmWbt2rVeatqJFi1r//v3thRdesHfeecd++OEH+/zzz613794u83jfffdFncGMZ3Xq1LEJEya4DGS4vXv32k8//WR58+a1cuXKeaUSToGjiIhIFiOTSNu2Bg0aeCVmhQoVsosuusi9RzbMlydPHrvnnnvs+++/t1mzZnml6VOgQAFr3LixPfbYYy6j+eqrr7qg9XBH8wCCcdZtONqVfvfdd3b22Wdb/vz5vVIJp8BRREQki5HFIisYbufOna4dXYUKFbySfWrXru2qmT/44AOvJGOKFy/ugtOyZcu6anK/6pWfM2fOdBlJqrbJsDVt2tTee+8927Ztm5sGZOH+97//2U033eSydWXKlLG6deu6dnp+NpSfTz75pKsqZzmOOuoou/32210VerCqlyp62m/SvpPvO+GEE2zYsGG2detWb4oDNm/e7N5r0qSJlS9f3s3j5Zdfbn/88cf+zCnzSpvQQYMG2YMPPmg1a9a0SpUqJcvehuvUqZMVLFjQZWSpvg76+++/XVV1jx49vJIDWCeffvqpde7c2WrUqGGlSpVyNwGvvfaa24ZgXU2ZMsXat29v1atXd+uidevW9sknn6TZVpK/YXszb5nZpjKrKHAUERGJMQIjghQCMAKMc845x3tnn8KFC9tJJ53kOlMcajs7AjoCqrlz5+4P9iZNmmSXXHKJa1t555132kMPPeQCwiuuuMKee+45FwzxvVSjn3feea56l+np/Xzttde6DClBHMtxww032Msvv2xdunRxGc5rrrnGBWZkOhcuXOi+j4CI4LJnz54uAKWKns8j8Pr666/dND6CtLvvvtseeOABa968ueukcuONN9rs2bPt0ksvtT///NObcp8RI0a44Ktv377ubwjsUlOkSBE3D1OnTnWdlYLef/9997fHHHOMV3IAzQuo7q9SpYr7noEDB7oAmPaorBuwPQnSWSfMP+u0Xr16NmTIENdeMhKC3F69etmJJ55or7zyissU53hJO4aIiIjEyLBhw0JJwVyoWrVqoaSgLPTTTz+F9uzZ4727T2JiYigp0ArlzZs3lBR0eKWRdevWLVSmTJlQUpDmlaTUpk0bN83vv/8e2rFjRygpeAu1b98+tHTpUm+KUCgp4AklBWZu3pKCs9CmTZtCbdu2DdWqVct99t69e70pQ6E1a9aEtm7dGho+fLj73NGjRyd7f86cOaGjjjoqdOutt7rfp02bFqpZs2aoY8eOoY0bN7oylnHcuHGhpGAsVLZs2dDPP//syseOHRsqX758aOTIkaGkANaVYdasWaHq1auHkoJD9/u7774bSkhIcPO3ePFiV5Ya3ifkSQruQjNmzHB/N3HiRO/dkFv/RxxxRCgp6HXrp2rVqqH//ve/+79/yZIloaRAObR9+3b3O9gujRo1CiUFzu73oUOHhpICUzffPv5+wYIFoaRgOJQUPIf69Onj5gN8f+3atUNnnnlmaMWKFa4sN1DGUUREJIaSghI33AvVx9OnT3dZp2D1MGjnSNtH2tolBT1eacZRTZ50zXeZRLKYVCPTCYdqW6poeW3ZssWSghiX0UsKDN1QPmTTqHamKpXqdh/zzmfSQ5kq25NPPjnZ+0xPB5+k4M5VLZONY7idpMDJkoI2Nw3LSHtCMqJBdPChmr5+/fqu57k/f2QL+dykgMubch+qlqmmjhZZRarJyTD6yCjyXWQ4aXsazs9EsixkbVkWMpasA38YocqVK1uxYsVcpyQyuUzL+mVZmPcgsrVJQbXLBCcF3S6TmVsocBQREYmhNm3auB7T9OBlqByqht98803v3QMIrLBnzx73M6MIYBifMF++fK5NIB1u+Ey+l+Au+KKtIG0RaXdIUEvVKVXmqaHKumLFiq4tZRAB0xFHHOGCT17Lli1z80GAGcQy0h4wiGrk33//3S688MJk80YbQOYpvIo52OEoGgSuLVq0cG0PqVZmvoYPH+7abzIGZiQMZ8Q2u+666+z88893nWyoimfYHn/78Le8P27cODevVM0TIBKwh6Oaft68eS4oL1GihFeaOyhwFBERyQZkociW0b6Njh7hCN4ISg41G0W2jmwaGUw6mRAs8d20wyNgCr4YO3LGjBkuwCNYoq0lQWBqmEfeJygNIiD0M3f0Vvan4/PChf8t30vmj2xmcN4YZog2l6NGjfKm3Ce97QLJ4tIRiM4xDD5O9nXatGkumAwPYsF0BNnXX3+9ywzTrpH5YZs1a9bMm8pctpF1+tlnn1mtWrXcTQGdaWj/Gd4Rh+wkY24yjifbJjdR4CgiIpJNCGIIIsI7TxAw/vXXXy6TR/XsoaDjCJ9Pxw2CNzKEZMHo2cyTZiK9yIIxX1RfE2imxg9EwwMjehiT5fSXj0CVTCafFy788YpU5fN3dCyJNG9UYR8qemvzPfTcJvNL1TIdg/wsbxBV02+88Yade+65rnqbn1SvExwyn0EEy3z2yJEj3dA+BOsEk7/99ps3xT700KacoJGe7ZHWS06lwFFERCSLkcUjkApHMEWVJUPYBNEWkSplqmiDbQfTi/aK9Oolk3bLLbe4Mj6TwJQnpPA94ai6JbBkHEiGnaGdYiRMw9AzzL//5BsfGcaff/7Z9TzmMwiyCFoZjieI4Jjq3iCydARavBeO72T+DhVtNGkywDomk0lWlyxnJGwjqtrJSAaRqQyOv0mwHEQ7VnpKsy7Cx+Nkm7Zq1cpuu+0212aTbRRpW+REChxFRESyGO3jyGgFAwgCCqoqCZLIOgWR5SLw6tatm1eSPmSw3nrrLevYsaN7SgqBCW34QMcQso8MY0NmLIjv5FGFZMLITNLOkGpZql39DjwEbrQPJKPG0DyUM2TO9u3b97/P91H96werVMuS4eNz/GCLgIzp/CF7fHwmASLt/4LBI9/DcECRBu/OCNY5j4KkcxJtDsOrzH1UhZOdpQqaecaCBQvcfPqZYoK+Z5991lWv+9OATjdkMcNvDMD3Uf3Ns7EHDx7sMp+5QtLGERERkSw0derUUFLA5oaBOeaYY0Knn366G/KFYWgYsoahcILuueeeUJMmTdwwMAfDcDxJwU2oWbNmodatW7u/Swr63JA2/D579mxvygMYEuf8888PlSxZ0g1nc8YZZ4SOPvpoN3+9evUKJQVUbrqkoDPUpUuXUOnSpd38Mt/HHXdcqEKFCqHPP//cDcHz+uuvu2Fy+L7mzZu7YXdYrjvvvNMN2eN75ZVX3DRJQVioadOmoSOPPNKtk7p167rp/eF4kgJPN9QO7zM/J598cigp8HTTMHSPP4yOPxzPqFGj3O9pCQ7HE8Q6K1WqVCgpmPVK9mFZ/eF4kgLBUN++fd264vtPPfXUUKVKlUJnn322W28dOnRw0/Xv398tG/PJ/LKd+Zsrr7zSre/w4Xh8rONGjRqFatSokSuG5cnDPy6CFBERkSzz77//uoGxqdole0bvXjrGUEUa7IBC9TJlDF1DVebBqqqpavXb0JHdopMGw7yQWaRHdKR2e6ATCp1NGFibLBntKRlyhipZ2ub5eI/pqFKmup35JoN4yimnuPkmw8hTaMgEkqnk+1kuehkHlwtkIVkHTMcTYXiyCkP1UO3Lk2FoM+ljwHIGKqdXNlgmOrUkBa4uW8cy05nnggsuSDGkTzgyi2RSGUiczKePbCM9nxkUnB7nPjKotKVMCgrdd5HBZVp6exM2MQ8MZ0TVO9uHQbxZTywfzRLIGLPszBdNA1hnrCeGQiJTy0DpPj6P6mo+n+3OgOs5mQJHERGRHIInrFAFSoAyduzYZAGcSE6gNo4iIiI5BG0MaddHJktBo+REyjiKiIiISFSUcRQRERGRqChwFBEREZGoKHAUERERkagocBQRERGRqKhzjIiISCpq1KhhiUmXyVJlDq2Hc15daSWL8RjJNWvWuPE069Sp45VmPgWOIiIiqahZq6b9XSKfFWpQ0yvJmAZL9z2OTySrMAA5j0JkSKd69ep5pZlPgaOIiEgqGjZuZItqlbCE9k29koxpN2W99z+RrLFp0yb39BkyjjwBKKuojaOIiIiIREWBo4iIxK0VK1bYiBEjbMiQIe5pLJs3b/beEZGMUOAoIiJxafHixXb11VfbU089ZbNmzbIHHnjAevTo4ar0RCRjFDiKiEjcSUxMtJEjR9rq1avtxx9/tNdee80+/PBDmzx5sg0dOtSbSkTSS4GjiIjEnZ07d9rYsWPtuuuus0KFCrmy2rVr22WXXWYTJ060DRs2uDIRSR8FjiIiEncY02758uUpepe2a9fOla9du9YrOWDSpEkusAy+li1b5r0rIlDgKCIiccfPKBYrVsz99JF15L2tW7d6JQds377dVW0HXwSgInKAAkcREYk7BIYFChSwfPnyeSX7FC1a1Hbv3m179+71Sg4455xz7Isvvkj2qlWrlveuiECBo4iIxB3aNdJBJvwZF2QQCSbz5tXlTyQjdOSIiEjcKVOmjMss8hi2INo3Fi9e3AoXLuyViEh6KHAUEZG4QzV12bJlXaAYNGHCBKtcubKVLl3aKxGR9FDgKCIicYeq6pYtW9qwYcNclTX+/vtve+GFF+yUU06xcuXKuTIRSR8FjiIiEndox9izZ0+XcWzWrJndfvvt1qZNGytRooRdf/31auMokkE6ckREJC41bNjQ3nnnHTv//PMtf/78ds011+yvqhaRjMkTCu9yJiIiIk7Dxo1sUa0SltC+qVeSMe2mrPf+J5I1eAb7+PHj7fvvv08x8H1mUuAoIiKSiswKHDPDqb9vtrKbNSC5RBarwFFV1SIiIiISFQWOIiIiIhIVBY4iIiIiEhUFjiIiIiISFQWOIiIiIhIVBY4iIiIiEhUFjiIiIiISFQWOIiIiIhIVBY4iIiIiEhUFjiIiIiISFQWOB/H555/bZZddZtu2bfNK4td3331nZ555pq1du9YriV/vvvuuXXDBBTZr1iyvJPdZvHixXXPNNfbXX395JfGNffPjjz/2fpP0mDlzprVu3dpGjBjhlcSvqVOnWqdOneybb77xSkQkMx32geOePXvs9ddft6JFi9p//vMfr/SApk2b2vTp061Pnz62d+9erzRtRx55pOXLl88KFSpkhQsXTvG68cYbbefOnd7UOce///5rEydOtF27dnklmY+TeqlSpaxAgQL2/PPPe6WRde3a1fLkyWPNmjXzSjIPwdbkyZNt/fr1XknOsm7dOnvhhRfs+OOPd+urSpUq1qNHD5s3b575j5evXr26FSlSxNq3bx/1jQ37cVr7ZpMmTWzRokXe1DkL++by5cu932Jr1KhRljdvXrffsp5KlixptWvXdjcf77//vm3evHn/dsmJ2M9Zf0uXLvVKMh/njdNPP90dswRuqWE9XX/99W66xo0b259//um9kznWrFljP/zwg61evdorEZHMdFgHjgsWLLB+/frtv5hGUrp0aXv88cftk08+cQ8PjxYXev7umWeeSfHq1q2b5c+f35vy8MTycyFLLeDhpE/GgAv14YYbFILmV1991Vq1amX333+/y3rPmDHDzj//fJc9Auvwuuuus3/++ccGDhwY9Y0N+vbtG3HfvOOOO6xcuXLeVBKOQJH1NGDAABfI46abbnLZvLFjx7rfD3fclEyYMMGWLFnilSS3cuVKmzZtmrtZF5Hc57ANHBMTE121zaRJk+ypp56yevXqee+k1KZNG2vYsKG98847tnXrVq80bWXLlrXLL7/cVSWGv7grTy1QPVywvln3GzZs8EqSe/vtt12Gp1KlSl7J4YMA8KijjrKRI0fa4MGD7dZbb7WHHnrI3njjDfvf//5nX3/99f7sVp06dezqq6+2Dz74wObPn+/KokEAFGnfJOuekJDgTSXhmjdv7tYTweKDDz5ow4YNs08//dRtj//+9782d+5cb8rD1zHHHGM7duywcePGeSXJzZ492zWzOOWUU7wSEclNDtvAkaDkhhtucO36CAypfkoNQR4XC9pXZWZVGQECVZL8pMp806ZN7veNGzfa7t27vamSo4qb95mOoCs8Yxf8nEjv+/hOqteowuLz0qqe9qflM5me4DlYLUcQzntcLPgcvpff+bvUEDiScRg9erRXcgDL/tprr7mq2EgBPd/HPPjfw/yHV/0zfyy7Pw3rhHWTFj6X6fm8tOY9qxUsWNAtPxdg9lNQrXfqqae6GxKqG5lX3//93/+5MjK0we1yqNjW27dvd5+5ZcsW9zvrh+0cSXDfY1r+Jjg/wc/x34+0nv1t50/HPKSFfYHp+F720/Dt7JezX/nzd7DPjFaJEiVc9f6gQYPc5xPEB7cNwo/Z1NafP3/+crNcwc8KHrO8WH/h3+Xz1wkvfxtGwt8Ht0n4+uN95p1XcPumdl4BwTXrhaxj+LLyeT/++KN7/7TTTvNKD2A+mV9/faU2/3xuWsd/JKwTps/OY1skHhzWVdXly5ePuiq0QYMGLvv13nvveSWHjqpHAgEySPfee6+1bNnSTjrpJNfup3///u5EF8SJmCxmo0aN7OSTT3YXLDJEtOcBd/F33nmnO3HzPi+qPMlGBU+WnGjJZBGI8Fm046TK848//vCmOIB2jw8//LCbN76PzOu5557rsl/+BYaqJ5bjtttuc+03+VwyYWl1PKlWrZqdeOKJ9sorr6S40HNh4TNpuxdencW0Tz75pHXo0MFlLFhXJ5xwggvsg1VjBPn8PfPCOiXLS4CVWrsnPpcglkwfGT6WO6fhoseFnfZ1BJI+LsJUaVNVGr4uDwWBK9XktLU855xz3PanrHfv3q6tZdDChQvdvkd7VNY3+17btm1d+2EQAFDFe/bZZ+9/n84uTz/9dIogzt92bFe2H007IjUTIXjh85mWz2Pf5PvJzrKefBznVCVTvcz7tBtlH8pM7MvM608//WRz5szxSs1++eUXt2+yn7LcHG+XXHKJO2b9YIifND+45ZZb3LHIZ7GuzzvvPNdEBuyPBKdnnHGG+xxebHPaCRNA+dj+1KRwjLI+CM6oUqc9bzjOAzSHYJvwnf70NHvwO8hxTuHYb9Gihft+/s90DzzwgHs/Em58yL6SWQxvL8uNJfspGe9w7AfU6rC9ObZZRs67/M650kdNBcvEOmK7M++s47Qy7mwT9kc+a9WqVV6piGTEYR04pgdtHbloZkWvTtqbceHghP3hhx+6rAUX62BVD0EjF2w6dQwZMsRNR3UuJ3KyplxYrrjiChck0k6NnwR3BLsEhVR7+shmPfbYY+7ky3QEbwQlXMSDCFyvvfZae/nll13ASgeB4cOHu84/BIn0TA7iO8gEvPnmmzZmzBg7+uijvXdSIvghwOVkT+cjHxdRMmdcYC688EKv9ACyIy+99JJrfM/ysz1YXjoosP7AhZRlJmBgXlhGAvMpU6akWpX47bffurauHTt2tCeeeCJHVpGzzWg/xsXdz0T6CIwJWtLKHGcE65WbjJtvvtn9n6pZLtxsAz/bRXDBBZn36fTA+uYGi+CBwId5YtuwnQiGeI9p+Rv2OfZ/H9uImgC2HdMQBBGo9OzZ05tiH76bY4RpCQTZFz766CO79NJL3f5MEBtEEMN8c+wwTxdffLH3TuYoVqyYC2Dg3zBxTF522WXumCVA45h99tlnXRDDvkawDfZJ1hvHE+X++mOZOT44JtgGvFinrBfe7969uwuG+Wyfv97Zf1l3BGJk7YPTgM9kW9LGm4CKv+N7OccQVPNeEE0kCN4fffRRt/4416SFcxg3f8EgGvzO/kKwGo5OLZyz2N6co1hfHL/cELLvg6CPmxnaSLIP+ucv9rHff//dTROO8osuusi1CWb7c9OaW82tUcSm1Ct+SK8lFQt5nyaSMXmSTiCZV7eVS3EyIkipUKGCOxFFQlUIF09OwGQ6uICnhsCKqsNIHWAqVqxob731lgv4fv75Z3fXXLVqVXeB4OIDqsO5I69cubK7GPJ93H0zD5xMObGGe/HFF10wx09O/j6yCvxt8eLFXUBGBo+LCplIshV+FT27AZ/722+/uRM+383FmMCRCwk/fWQjuFjXrFnTXUz4nWplvoffCQpTQ69qLlQEC2SKyGQwv7QzBRdbMjJkgglSufDS+cPPmJA55QLDevQx7wSpdOr48ssv3bonw/Pcc8+5ANLHdATDrAuCQ4IWvoP1QfaGFxeutJotZJevvvrKBcs0q2CeyTIGEajzPpmZSPuHj8CEAITmF8GspY9M91133eX+zzpmfXFTE7wJoH0f88O+wnZivyMgItjo1auXN9UBBFJkxsmWBQMStiUZagIAjgW2GS+CQoKjunXrelOaCwhZbr6HvyHYIvA87rjjkt0UUd171VVXuWOM3rr+CAdlypRxgdlZZ53lTbkPy8pyREIw7geg3DRxjiDwCO5TQew73GCxb7GeCU5ZdpaFzJmP+apfv74LeNj377nnHneMEfiTkQzHTd0RRxzhpvO3Ddif+R6WlWOWamSOa4JkglKWGdzMcUxxk0Wgeffdd7uMLNuU45pt7mPds3zctBLgETCy7aiN4NjivJUagjfWL1lAOgZSK8ANAOcRHwEn245twfKTfWT90EOd+eQcFzx/MD+0JWW7sx4IPJkfpmef9/dhMq3sT5yXGUKNoJvjn/MrQSPnFWp2qAlJr4aNG9miWiUsoX1TryR3q7lqhzVYmjlNNSRn4RzANfj77793ia6sooxjlKh+4WLNiYxA5mDoVc1dMsFJ8MWJO/zkRVWwHzSCwIbAza96IdgiuOWkTfVdOE62ftaOC0cQJ2F64lJFywWFCwIXVwK2YIDECTiYReAiwM7HCZkAgkDBf/FdZGA5ka9YscL7i32diJj3aHExJcjhe/x1SnaB+SRrEglBABcj1gdZBy4SXDjZLiwXFx/WLxdFsihc7MhSgmUMzh9/Q6aRaj0uMFzscmLQSKBB1SCZkkceeSRF0Aj2H+Z92bJlXknaCNzD901eBPVBXKQJvoJYv3wPgQvbgf2BGwcu0JEw/wTzVMUGsS35PrKn7FdMR2DATQmBQVAwuAGBDNOzHwf3TXrq+9lY9iMfJ1GCtXDsS8x7pBfNL9LDv1FkvXAzRbDJ57NPB+eR+aYDEpkw9kH2YfbBSEEjuFlk24YPS8X+zPJz/BOAEeSxnglY/aAR/C3ngCCyhlQNsy8F543giu3C5wTPc9zcEkhHi3XBtuUixs0ruOFjWcjM8nnhmE/OV9QYEHAzP9wUsE/4n8F5lWOb5ixkVPlM8H3hN/NkernJYX/gPJCRoFFEUlLgmAGRMjXhuOgQiBEABV9kZDj5BYU3EufETaDqt9PiBEggRxuqSN9NRpI7ajJnkYIKLphkjrgQkF0heIpUFRvM4jH933//7e7iaT9ExiL44uJHoBZsJE/GlnmPFid01gnL5w8xQ3Ui4xZGajgPLrRUl5FdIwNEMELGivnlgs37jG1I5pW7LzI6BDT0fOW9IL/dHUFQjRo1cmQVFvNMdSIXcqrtgpmrIJYd4VXYqSFbF75v8iLjF0Q1Z/hnsn79domsQ4Ikmh2kloVn/bLfRrpwk0njPbJbvFiOWrVqpdiPmC6Iz+SYuO+++1Lsm36tgR9sgOMiUm9xsqXsP5FeZC7Tww9iOPZZFm66uLkhax6cP7JhzJvfNpGAL7WgERyz3KhFmn/KWbZff/3V3cjxmdwEhSOADSLDyzHDjUhw3vzMLtvBXx5E2iZpYZsyH2SkySiCAJkbO24wI9XGcD4hI01zBmpc2B/JjpOh9I9dAmJuyAk+yTx37tzZHevBNq0+Mo7cKHNcR+pkJyIZo8AxStzVc7LnhBcMsDJDalkuPxjgAsT/U7sw8x4n1tQ6+jDP/jRk37gARJo2GJQyLUEjnUUIOMNfXAAIHskO+aINWoLIkPK9ZFX5Pi4ydJpILXNJOzmytnwv7T6pkqOKj6A6iGpnOiAQGJC94Hu4KDLfPr6P7AxBFMEGGY6chO1OG74vvvjCdfhILZgGF06WjQA4M3EDE4m/b/r7CcFkaniffSPS/uEHEEzjB6OR9vPgvgmCRuaNjGf4vskNA/MVbBfJ34d/RmZifRC8sYxk0Zk/0HYxfP54EST57Q79ZUkN06a2/vxypuHFPhPN+IjsK2R1ybiHzxvnOZYnmKFNT9DoO/bYY913EMCxjNy8EfzSUSkSOqdxvIJsIuPs0rmI6vggbp4ICKnqJlCmMxvNXsI74vBdrH+qtNmnCH650eBcLiIZp8AxStyd0/aQdnypBWhZhUwe35la428u2mQ5uIiG91AFwRUXE6ahCpxpyBSF4+99fCZ397Sd8qt6swIXPTKCtL8kAORiQZVYpAsp1eK0IyOTQQ9PLgTgIhfMjvioviXQpCqVdltUHfptKcF6JbPBBZyMBNXBZPZyArYR2ZahQ4e66jaC27QCH6puaePpr5NYIcCnepG2lQRrkVAtSUBDZjkc25TtR9Uw+xvLGNwPfeGDSZO1J9jMKU+5oVqc7CK9gbmpIcvlLwsBXVpYP35HmUgIlAjmImXV/HL2X45xbkIjfRYBYRBBIUEXQXZWYb+gzSPzQ5UzPfHJvkYKbFlHBI6cowgKOcYJVtk3WMZwnDc4dulMRRMLspK0gwyi+p+bRrYJ24IsJdlUalD4XBHJGAWOUaIaiItzly5dvJLY4YTHSZj2R5ECG4JKshycfGnLE0TQxx03QRIXC9pJcqHhTp6LuY+LPnf5Pk7uBMl8Jm0FI8msO3ca0XPiJ1DiIhpeXerj4sc8syxUZ/u4eASHEiLIDyJDTGaRi2qw3ZuPqj4yegSf9AYNVr9nl88++8z1RKa6lPaIB8si0bO+adOmaWausgI3IrQfZL2SvQrH9qJNGtuV6t8gAj+yxux7ZIgJkNhGZO7Cg0fanwbxnQRnbLdIYrkNCfKZD27GyIKRRWXeaJPIspCZD8ey8yKg4ZikGjfYXtjHNFTHsk9zzAYR/HCzRRDFcEkE0+zrHMfBzDrzR9Y6iM9kGm7YIsmsY5vgjn2A6mSavpABjIRl4X2aJASb2zCPwZEs+CzWiY8bF5qjEDiH31hznqB3NsEimXhuPjhPkvmkaY+IZIwCxyhx58qdL50FosHFkJN9pJdfjRUtLgj0piQ4oiqHzCefQ1DISZWqHNr7kbUhyPDbL9H2jI43dLKhtyefw4mTqmAu4lw0+Aymoz0RyxjEcD10jGAoG76HgJPP5aJOdo5xETMDgQVVWvQgp5csv0fCxZhMKBdjqraZF9p/3X777e7/PnqNEgCSvaSczAoXTtZ7ak+rIOgiSKNzBdVZwYtTrJGhYf4JoKmWJzBgOfxXMCgANzV0MKJtWLTZcIKJ4GcGPzs92RgCPXrmsl3I6hLAsk/xItNL8MQ2JfPEjQE9bHmP7+ICTpDDEEh08iDjSHaV/ddvt8aLjDAX/yCyemSU+HuGZyHo5zMJ3hiChpuerMA+5K8r1jv7LDdkBM20l/XboLLNmG/aYlKVSlDI37DsBJJkvejgQeBI4MN2Yx8ka+mvH97n2GO/51hkXwiuX24uyLLxWbR1pA0pn8FNmB/Isv5oG0sWL4hzBe2taS/MsEZkHvlOftLOkEx9ZmCeaP/K8Uo7zvC2qj7WF+capmNfZvk4zxB4sj/46NTDuuBc5a8H3uecQG/uIL6L72f0BzrlcFxxvuDYTi0LTLn/uf4rtUy6yOFKgWMUOJlwcqW6MFKnkki4OJAF4KQZ/qKaNb3BI4EdQ3ZwMqU9Hy+qcxiqggCDzA9Vsdx5M74bFxAu2vS25OJDWzkfF3DmgzZ/BFJMR5AVPlYeDeoJGKk6Jjjj+2hnx/S0B+RinxmYd076XDxS65kL5oeqZrKvtFlkGbjoEpQEe5vThopgmbHi/PXE8B9cYFPr8MAFnMCHtlJvvfWWa/OYXdVZVL1xk8KNAkF+cN/hxb4QvPCxD3CBZNpoETSEfy4v1mekzFda2Ce4MHPh9/cp9j/2J/5P+zJuYOgsxk+2B9uF4IRsM8Gkj6Cd6dgGZNr5bMYRJWgKIrPKcvvjRvI9zD+fTXYyfHSBzMIxyPewfMwb88VxwLEX/p0MJ0QQRjDOsvj7ItuJwN3vJMfxRNDJDROBEtPw+dw80PyAfZObIT6fdcr7HC8MD8YNIT9B1S69z7mJZJ2yTphH5oH9OohjjfVP0M/+xg0l30lwR5vEYPvGQ0XgTBY2rdoa3ufYZN3SA5x1RScaso8ctz7aXHPuZL9hnbIuON/RWS44XTjOi9xgE8j7zXAiIRhnewZfdF4SkQM0jmMSTkTcsXIxijTcDVW1nHTIenAiORg6ZXBhSA0ZBC4q3M1yh01gFuwgwx0x1S5kyhj7zkc5F3Uyjnw+80vVFNk6LgQgC8KJjswBWQwCXU624Y3bqfZlOqr0+G7axvH5tEPiO4MdFPgspiWDwe5C20EuemQtuKhRrUUmhOpDytJCQER7OLIAwfZ4VCMRbHPx8qtlqZZiPbB9gtkE2rWxHnifYJLlY8gO5p8LH/PO+7zIuLBuuACzzv2qXL6PNndkw8jW+Kguo9rVz1awfLFGwJjWoy2ppueiyXIxr1R1kpEmG+3vB6nhBiGtdpxcqDkGuLjSw53tFN7hhvVKVouAPfh9ZP1Yr+wvrDfaq7HO/X2J/YSAnn2U/YiLN9suvCMUxwXZIaYjoGBf45jhuArfx9gHWCaqHgmm2ZfZJzgm/H2eJh5sf5brYOsnNQxnFRzvkc9mP2UZWT+pNREgW0U7YfY1jlm+n04b7PvhwQvfwXTss6w/fzn8cwPlHCOcF3jfX3/BobxA5pDjmGON+WTdsQ3Yr/i84HHHPPGZrGvWJdNxzmD/Z5l43z83ptaExMc2pTqdGzuOHR/bnW1HcMr68vG97DP+/sbfs67Yhzjm+RyCac47/o0g+Bv2YfYz/ob1yXrwj2Pe57ggWPRv9JmOMTjJxPK0odR6dnNeDG8327N3L/u7QUWN4yg5HsdELMZxVOB4EJxICOxoExTezkokO3FxZUgSLpIE7pEuhCKyb0gzzuNkWVNrZ5kaDQAuuUWsAkdVVR8Ed7pU/aT1bFaR7ECWjWwS1cQKGkUiI3tN23Qy5FRri8ihUcZRRETiElXftOOk+poxYrnRSi9lHCW3UMZRREQkg2jzSmc62nsyTFlGgkYRSUmBo4iIxB164zM0E7266U1NRztedBKiA5aIZIyqqkVEJO7QI5uqanrlB8c3pYc4QxAxGkE0VFUtuYV6VUfA0BAMb5EdQ6SIZASHV/hwKdmBYZeYFx07khv4l6WccOwocJTcQoFjBIyh+Ovvs610xQpeiUjWKbjn0A4Nxq8jYGMMzOBj1LID2Ze1mzZYyXIHxtETyal2Jh03idt3uXFVs1u8BY5lN+62qmvS9wCKcPkSQ1ZlbdrPYJfYU+AYQbt27Wz84t8toXNzr0Qk6zSZt8Xy78344cHAxQxUTLuq8EGuY40Bw+fm3WrFz86aR/GJZKZdC5dbqVnLbOnC7H9qS7wFjpmh0K5Eaz1jo/eb5BQKHCPgkVtjl8+1Mtd28kpEsk6bnzdYgUMIHHkSCA3xeWZzdgeOPMptVpEdVqpHa69EJOfaPnOhlZ04zxbM/t0ryT4KHFNS4JgzaTgeEREREclRYho4MiTC/fff70bx57m6PKtURA6OY4XHpXHs3Hnnna63qIiISKzFLHBk5P4rr7zSPv74Y/ewfJ6v27RpU/cMURFJ3eLFi+2SSy6xCRMmWMOGDV01BD8VPIqISKzFLHAcM2aMbdiwwT7//HO7++673eOfGjRo4DKPjPAvIpGNGjXKihQpYhMnTrR+/frZ6NGjrUKFCjZgwADbs2ePN5WIiEjWi1ngOHz4cPeQeQZjRenSpa1Xr172yy+/2KJFi1yZiKT0ySefWJcuXfZ3sClfvrx7/u60adOUdRQRkZiKWeBI1fRRRx1l+fLl80r29fTcunWrG7IkHG26GEIk+CLjInK4oaq6Zs2ayQbvbt26ta1bty7iOHeTJ09Ocez8+uuv3rsiIiIZF5PAcePGjbZr1y4rWbKkV7IP2UfKqcIOx4DJHTp0SPaqVKmS967I4YGxIBkxK3w4n2rVqrknKUV65i7V2OHHTpkyZbx3RUREMi4mgSNP0CBbEnxeKAoVKuQuipHaaVWsWNH69++f7FWvXj3vXZHDw44dO1yWPpipB20e9+7dG/HY4Skx4cdO9erVvXdFREQyLiaBY+HChSMGiGQb8+bNmyKgFJF9CBB5PjtBYpAfUObPn98rERERyXoxCRwTEhKsaNGitnbtWq9kH9puFSxYUNVoIqmgeQfBIU8ECKINcLFixdyxJSIiEisx6xxDA/2FCxcmG3qHceloy0inGRFJiSYeVD1z7ASfDsqwVuXKlbOqVat6JSIiIlkvZoEjg39/+umnLstItduKFStsyJAhrmc1PUZFJLJu3brZ22+/7XpR09xjyZIl9uSTT9rpp59ulStX9qYSERHJejELHFu1amXnnXeeXXzxxdajRw+78MIL3UO4H3vsMW8KEYmkU6dO1qRJE2vbtq07di666CI788wzrW/fvt4UIiIisRGzwJG2WPTufPbZZ93A34888ogNGzZMGRORg2AYqscff9wGDx5svXv3tkGDBtnQoUPdQOAiIiKxFLPAETT0P+2001zm8YwzzlCnGMkyeRNDh/wyO9CmMLtxrFA1zbFD8w51ihGR7LQ3z6G/JHfKEwq2uM/hunbtamOXz7Uy13bySkQiazdlvfe/7LN69Wr7448/bPr06SkG8I41gs1ZRXZYqR6tvRKRnGv7zIVWduI8WzD7d68k+zRs3MgW1SphCe2beiWSWXLCeTqeMPrG+PHj7fvvv3dNAbNKTDOOIiIiIpJ7KXAUERERkagocBQRkbhGi6xffvnF3nnnHdu2bZtXKiIZocBRRETi2vr16+2aa66xnj172po1a7xSEckIBY4iIhLX+vXr557trictiRw6BY4iIhK3PvvsMxs7dqzdeOONVqBAAa9URDJKgaOIiMSlpUuX2sCBA90DJxo0aOCVpm7q1KnWp0+fZK9Vq1Z574oIFDiKiEjcoUPMqFGjrFq1ata9e3evNG0EiYyBF3xt3brVe1dEoMBRRETizvz581019W233eaVHFznzp1d1jH4ql27tveuiECBo4iIxJWdO3fazTffbC1btrTjjjvOKxWRzKDAUURE4sqIESPcoz7bt29vS5YssQULFrj2jrt377bFixfbihUrLDEx0ZtaRNJDgaOIiMSVIkWKuGf13nLLLXb55Ze71/33329///23/d///Z89+eST7rm+IpJ+ChxFRCSudOjQwd57771kLwLH0qVL2/PPP2/33HOPJSQkeFOLSHoocBQRkbhSvHhxN9h38FWuXDk3CHjFihWtbNmyljevLn8iGaEjR0RE4l6FChWsY8eOVqxYMa9ERDJCgaOIiMS9evXq2YsvvuiyjSKScXlCjJKaS3Tt2tXGLp9rZa7t5JVIZjlr+gYrvDvX7Aq5wurVq+2PP/5wvTupOstOzZs3t1lFdlipHq29EpGU8iaG7NxpG7zfsg89oZctW2Zz5871SrJPw8aNbFGtEpbQvqlXIjlJs9mbrNTWvd5vhzc6fI0fP94NXE/nsKyijKOIiIiIREWBo4iIiIhERYGjiIiIiEQlZoHjypUr7eGHH7bTTz/dGjdubA0bNrQrr7zSjeIvIpHRZuWll16ys88+20488UR33HTr1s1mz57tTSEiIhI7MQscv/jiC1u0aJH179/fhg8fbgMHDrRvv/3W7rrrLj36SSQVNHLm2Lnhhhvs7bfftiFDhtjGjRutd+/etnevGoSLiEhsxSxw5Jmhr7zyip111llWv359l0Hp1KmTzZgxw/79919vKhEJIsP40UcfuWOF44be0V26dHEZR569KyIiEksxCxwrVarkRu0P2rZtm+XPn98KFizolRywdetWmzBhQrKXAkw53PDEC46RoB07drinXvA83kjWrl2b4tghSykiInKosq1zzMKFC90FrVWrVlaqVCmv9IBVq1a5h9EHX3PmzPHeFTk8cfPEOF0cNzw6LZJ58+alOHYYF09ERORQZUvguGvXLnvhhRdcVvHRRx+1PHnyeO8cULt2bfv555+TvVq2bOm9K3J4GjNmjDsWXnvttVSftdusWbMUx87xxx/vvSsiIpJx2RI40mbryy+/tDfffNMSEhK80pS4MAZfkQJMkcPFlClT3I0WHcyqVKnilUamY0dERLJCzANHAsb77rvPrr76ajc0j4gcHFnDXr162TnnnGPdu3dXICgiItkipoHjb7/9ZldddZWrSrvpppsidooRkeQYA/WOO+6wChUq2FNPPWUlS5b03hEREYmtmAWOPLCeMRubNGni2jeG97AWkZQYeeCBBx6wUChko0ePtgIFCnjviIiIxF7MAsd+/frZ/PnzrW3btjZp0iRXZc2LntXr16/3phKRoAEDBtgnn3zielFPmzZt/3HDi5EHREREYilmgeM333zjnhxz3XXXucHA/dell16qYXZEUkEv6n/++ccFkB06dEh27EycONGbSkREJDZiFjguX77cPVpwz549yV4rVqxQJxmRVHBTFem44dWjRw9vKhERkdiIaecYERERkcyyoHoRm1m76CG9VpZV2/H0UOAoIiIiudK/pQrYynKFDum1qWjyx7pK2hQ4ioiIiEhUFDiKiIiISFQUOIqISNyaPXu2dezY0SpXrmxHHXWU9enTx3bv3u29KyLppcBRRETiDoPmf/rpp3b55ZdbjRo1bNCgQXb77be78U8VOIpknAJHERGJO1u3bnVPKbv55pvtueees4svvtiNI/z6669bkSJFvKlEJL0UOIqISNz57LPPrESJEta5c2eXYdy0aZMrL1iwoOXJk8f9X0TST4GjiIjEnVGjRlmpUqWsb9++dtppp9mpp55qbdq0sV9++cWbIqWPP/7YTjzxxGSvhQsXeu+KCBQ4iohI3CFAnDJlih177LH23nvv2VtvvWUFChSw3r17p/qc95NOOskefPDBZK+KFSt674oIFDiKiEjcITikFzWP5uQnQSHZxz///DPV57xXr17d2rVrl+yVkJDgvSsiUOAoIiJxp2TJkla3bl3303fCCSfY3r177a+//vJKRCS9FDiKiEjcOeKIIyx//uSPkiNopGMMVdYikjEKHEVEJO60aNHC5s+fb1u2bPFKzL7//nsXTNapU8crEZH0UuAoIiJx54YbbrAFCxa4cRtp1zh58mQbOHCgnXLKKdaqVStvKhFJLwWOIiISd2rWrGn33XefG2KnZ8+eduutt1qDBg1s6NChVrx4cW8qEUkvBY4iIhJ38ubNa127drWxY8fa+PHjbdKkSfb888/bkUce6U0hIhmRJ8QDPXOJZs2a2fQ5v1mximW9kpS2bdvmGj/rkVLpU2RHYpp3ETt37nRPX9CdevRYZ7t27XI9OHmCRXaqVauW/b1xnRUtV9orSU7bN2vs2bPHduzYkXvWa9LVoNjORO+X7LN9+3ZLTEy0tWvXeiXZp2HjRraoVglLaN/UK5F4U2ntLqv+707vt4zJt9es7OY93m/Zg6cjcZNEW95jjjnGK818uSpwHDdunG3YsMGKFi3qlaT0yCOPuEdK9enTxyuRzEB1z3fffWeDBw/2SuRg6MFJ4NilS5cUvTtjje1HYJjaDdU777xjP//8s7ZvJps5c6YbeFrrNX3YVzl+LrjgAq8k+yhwlGgU3b7XWv2677GW2UWBYwadf/757uLIhVAyz6BBg2zkyJE2ffp0r0TiSf/+/W3MmDHavpnsq6++srvuukvrNRdT4CjROJwCR7VxFBEREZGoKHAUERERkagocBQRERGRqMRdG0cREZHMojaOEg21cRQRERERCaPAUURERESiosBRRERERKKiwFFEREREoqLAUURERESiEjeBI4+o4rFqLVu2tOOOO86aNm1qr776qnvkm2TMunXrrFKlSla9enWrV6/e/lfjxo1zxDNkJXNMnjzZOnfu7I6bk08+2R5++GHbunWr965kxL///mt58+a1GjVqJDt2TjrpJG8KEZHcKW6G45kxY4ZddtlldtVVV7mgcfbs2XbPPffYgAEDXLmkH4Fj/fr17f7777fTTz/dK02620i6INatW9fy5cvnlUhuxbPf27Rp4264LrroIlu+fLk99NBD1rFjR+vXr583laQXgSM3XUOHDk0WLHLMEEBK7qHheCQaGo4nF3r99dft+OOPd0EiGbGePXtap06d7JlnnrHNmzd7U0lG1KxZ04499tj9L4JJBY3xgaw8brzxRnfcdOjQwS6++GKXdVyzZo17TzKuVq1ayY4dBY0iktvFTeD4zTffWKNGjaxYsWLu9zx58ljXrl3dxW/evHmuTDKGpDRV/nv37vVKJF588MEHdvTRR7vmCOC4OeOMM9w2//HHH12ZZJyOHRGJN3EROO7cudNWr15tlStX9kr2adCggW3fvt29Jxn33HPP2ZVXXumaAZDBXbFihfeO5Ga0C16wYIEdeeSRXsk+ZJhpjrBo0SKvRDKCoHHQoEF2xRVX2NVXX20vvfSSsrgikuvFReBIvT4n6aJFi3ol+5QpU8b27Nmjhv4ZVLBgQevRo4edc845rt1oiRIl7IEHHnBlrHPJ3bZt2+ayYSVLlvRK9mE7Y+PGje6npB/HDgFj27Zt3bFTqFAhu+uuu+zSSy/1phARyZ3ionMMDdFpCEo7Rxr1+wgay5Yta6+88opdeOGFXqkcit9++811oiD7eOutt3qlkhsRGFapUsUefPBBu/32271Sc9WqBI933HGH9e/f3yuVQ/Xdd9+5wJF1qg57uYc6x0gstZuy3vtf+qlzTDokJCS4jCMZlKD169db/vz5U2QiJePYGcmgfP31116J5FYcFxwf4dnjLVu2uJ/hmUg5NAx1RPOZzz//3CsREcl94iJwpBqofPny9s8//3gl+8ydO9cKFy5sFSpU8ErkUNH2jWCDqjjJ3QoUKGC1a9e2JUuWeCX7LF261BITE11bR8k8jETAS8eOiORmcdOr+txzz7WpU6fuz5bQ8H/kyJFWtWpVN+agpB9NAMLbh9KZYubMmW7AaMn9aK/KDRbBIqimJptMNvK0005zZZJ+q1atsh07dni/7cNYs3Q4UrOZ2KEmauXKlfbTTz/Zt99+664RbBsRybi4GQCcYIaev61bt3bDicyaNcv1Bh48eLB1797dm0rS48UXX7QffvjBDQ5drVo1V/X/5ptvuizuG2+8YaVLl/amlNyKbcrYjWQeu3Xr5rKPzz//vOvYcdttt3lTSXrx4IGFCxe6Y4d2pNSGMBg4xxHHDtleyXqcv+jQR3teBmQniCxVqlSKhxqkRW0cJZZyQxvHuAkcWQxW1n333Wdz5sxxQ4zQ6J+nYlC9KulHxpHhd0aPHu3u0jnhEoTfdNNNqv6PI4xzeu+999rEiRPddiVg7NWrl4KbQ8Dx8vjjj9u4cePccGB00uPGlmF5dMMVGwzT9p///Mc1reGGl/2ZGhRqp6iJGjZsmBt542AUOEosKXAUERHJBjRb4vnrjJ/JsEg+HhbBiBAMfl+nTh2vNHUKHCWW1KtaREQkG9ARieppnr8eRI0UtSeRRtugidNjjz2W7BXe6VLkcKfAUURE4g5tsRlv9qGHHrIXXnjBBYVPPPGEa87Us2dPV10dbvHixTZq1KhkLw2EL5KcqqpFRCQu0U6brOF7771nxYsXd53BrrnmGldVHW1bU1VVSyypqlpERCQbMCQbHSTpST1ixAj76KOP3NPFGG5q4MCBKR4YISLRUeAoIiJxh97sX375pRsloEWLFla/fn0777zz7OWXX7YPP/zQjakpIumnwFFEROIOgWGRIkVSPDqTsTQZqsd/WISIpI8CRxERiTtHHHGErV271j0txsejNKmuJqBMSEjwSkUkPRQ4iohI3CGz2KVLF7vhhhvs8ssvdz2qO3Xq5J4awyNTjz76aG9KEUkPBY4iIhJ3eGLMo48+ak8//bTrbUqnGKqteWIMQ/ToyUgiGaPheERERFKh4XgklvTIQRERkVxMgaPEUqFdid7/0m/3mo22+uXRNmP8JGtQR+M4ioiIiMS1nQXzZvi1q0AeC+XN431S1lHgKCIiIiJRUeAoIiIiIlFR4CgiIiIiUVHgKCIiIiJRUeAoIiIiIlFR4CgiIiIiUVHgKCIiIiJRUeAoIiIiIlFR4CgiIiIiUVHgKCIiIiJRUeAoIiIiIlFR4CgiIiIiUVHgKCIiIiJRUeAoIiIiIlHJE0ri/V9EREQC6tWvb8uqFLFiLRp6JSI50971m23DuxPs14k/WIO6x3ilmU+Bo4iISCqqVKliOy3Ripcq6ZUkt2HDBtuzZ4+VK1fOK5HMsG3bNtuyZYtVqFDBK5GD2bNnt21Zs96m/viTHXOMAkcREZGYW7lypfuZN2/kll19+/a1RYsW2ahRo7wSyQwffPCBvfrqqzZu3DivRKKRmJjogu38+fN7JZlPgaOIiEgGXXvttbZw4UL75ptvvBLJDMOHD7fBgwfb9OnTvRLJKdQ5RkRERESiosBRRERERKKiwFFERCSDatWqlaUdEQ5XZcuWtWOPPdb7TXIStXEUERERkago4ygiIiIiUVHgKCIiIiJRUeAoIiIiIlFR4CgiIiIiUVHnGBERkQzYtWuXLV++3DZu3GiFCxe2atWqWYkSJbx3Jb146sm8efNs+/btXsk+efLkcT3XixYt6pVIdlLgKCIikk48n5pH4r399ttWpkwZ27Rpk9WpU8eefPJJK1ky8nOtJW2swxYtWrjH5VWuXNkrNStYsKA98cQTduSRR3olkp0UOIqIiKTT/Pnz7dxzz7WnnnrKWrZs6TKPPXv2tObNm9uzzz7rTSXp4QeOt956q3Xu3Nkr3ad48eKpPi9cYktbQUREJJ2eeeYZa9SokbVq1cpKlSrlBqu+9NJLXQZy5cqV3lSSEVRJJyQkJHspaMw5tCVERETS6auvvnLt7oLV0gSRtHv87bffvBLJCCpCt27dajt27PBKJCdR4CgiIpIOBDQrVqywqlWreiX78PjBvXv3uvck42666SaXwa1fv75169bNZs6c6b0jOYECRxERkXQgG0ZWrEiRIl7JPrTDozy8V7BEp1ChQi5oHDJkiD3//PPWp08fW7p0qXXv3t1mzJjhTSXZTYGjiIhIOuTLl8/9DO9bynAyUHu8jCFwvOyyy6xr16523nnn2XXXXWefffaZy+QOGzbMm0qym/ZuERGRdKCzBkPG0As4aN26dS5o1HA8madcuXKup/qsWbO8EsluChxFRETSgeCQ9ndLlizZn2XEnDlzXEBZs2ZNr0QOFW1GaRpQvnx5r0SymwJHERGRdKJKderUqfbXX3+532nX+O6777qg8fjjj3dlkj6LFy+2ZcuWeb/tw5Nkxo0bl2JcR8k+GgBcREQkndavX+/a4pFxpOfv9OnTbcyYMfb++++7AcEl/UaMGGEDBgxw64/ge82aNfb666/bySefbC+++KKVLVvWm1KykwJHERGRDKCqevDgwS7zWL16dbv55ptdezzJGIY5+vjjj+3DDz90QxrRS71Dhw4uu6tngOccChxFREREJCpq4ygiIiIiUVHgKCIiIiJRUeAoIiIiIlFR4CgiIiIiUVHgKCIiIiJRUeAoIiIiIlFR4CgiIiIiUVHgKCIiIiJRUeAoIiIiIlFR4CgiIiIiUVHgKCIiIiJRMPt/8yXbc9jOrs4AAAAASUVORK5CYII="
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "6307823d",
   "metadata": {},
   "source": [
    "# Transformer로 번역기 만들기 [프로젝트]\n",
    "\n",
    "\n",
    "## 오류\n",
    "\n",
    "## 전체적인 오류\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "- 여기서 linear층에 tensor가 아닌게 들어간다고 오류가 계속 뜸\n",
    "- 대충 이런 내용\n",
    "```\n",
    "raise TypeError('Inputs to a layer should be tensors. Got: %s' % (x,))\n",
    "TypeError: Inputs to a layer should be tensors. Got: None\n",
    "```\n",
    "\n",
    "```\n",
    "after dot product :  <class 'tensorflow.python.framework.ops.Tensor'>\n",
    "after combine :  <class 'NoneType'>\n",
    "```\n",
    "\n",
    "- combine_head 함수 이후에 갑자기 type이 NoneType으로 변경이된다\n",
    "\n",
    "- return combined_x\n",
    "    - 함수끝에 이걸 안써줬었다..\n",
    "    \n",
    "## 마스킹 오류\n",
    "- 몇번은 잘돌아가다가 중간에 멈춘다. 왜인지 이유를 찾지못하고 끝났다\n",
    "\n",
    "\n",
    "```python\n",
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "# 여기 코잘마스크를 만드는 부분이 노드가 다르다\n",
    "\n",
    "def generate_causality_mask(src_len, tgt_len):\n",
    "    mask = 1 - np.cumsum(np.eye(src_len, tgt_len), 0)\n",
    "    return tf.cast(mask, tf.float32)\n",
    "\n",
    "# 읽기 모드의 코잘마스크 만드는 부분에서 오류가 난다.. 왜인지 모르곘다\n",
    "\n",
    "\"\"\"\n",
    "def create_look_ahead_mask(size):\n",
    "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "  return mask  # (seq_len, seq_len)\n",
    "\n",
    "\"\"\"\n",
    "# 위에서처럼 tf.linalg.band_part로 마스크를 만들어주는데 여기서 오류가난다\n",
    "\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_mask = generate_padding_mask(tgt)\n",
    "    \n",
    "    dec_causality_mask = generate_causality_mask(tgt.shape[1], tgt.shape[1])\n",
    "    \n",
    "    dec_mask = tf.maximum(dec_mask, dec_causality_mask)\n",
    "    \n",
    "    dec_enc_mask = generate_padding_mask(tgt)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask\n",
    "```\n",
    "\n",
    "- 결과가 이게맞나?\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6b3d628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    " \n",
    "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "font = fm.FontProperties(fname=fontpath, size=9)\n",
    "plt.rc('font', family='NanumBarunGothic') \n",
    "mpl.font_manager.findfont(font)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1d0ae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import random\n",
    "\n",
    "import sentencepiece as spm\n",
    "import tempfile\n",
    "\n",
    "import seaborn # Attention 시각화를 위해 필요!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99bd203",
   "metadata": {},
   "source": [
    "# 데이터 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68edd418",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/AIFFEL_quest_rs/GoingDeeper/GD05/data'\n",
    "kor_path = data_dir+\"/korean-english-park.train.ko\"\n",
    "eng_path = data_dir+\"/korean-english-park.train.en\"\n",
    "\n",
    "with open(kor_path, \"r\") as f: kor = f.read().splitlines()\n",
    "with open(eng_path, \"r\") as f: eng = f.read().splitlines()\n",
    "assert len(kor) == len(eng)\n",
    "\n",
    "cleaned_corpus = list(set(zip(kor, eng)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85cad230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'President-elect Barack has a full slate of pre-inaugural events today, including a star-studded concert this afternoon at the Lincoln Memorial.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_corpus[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0bb90a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_corpus(kor_path, eng_path):\n",
    "    with open(kor_path, \"r\") as f: kor = f.read().splitlines()\n",
    "    with open(eng_path, \"r\") as f: eng = f.read().splitlines()\n",
    "    assert len(kor) == len(eng)\n",
    "\n",
    "\n",
    "    cleaned_corpus = list(set(zip(kor, eng)))\n",
    "\n",
    "    return cleaned_corpus\n",
    "\n",
    "cleaned_corpus = clean_corpus(kor_path, eng_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d04c187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    \n",
    "    sentence = sentence.lower().strip()\n",
    "\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^가-힣a-zA-Z?.!,]+\", \" \", sentence)\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19834eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /tmp/tmpzeb988f4\n",
      "  input_format: \n",
      "  model_prefix: tk_model/ko_tokenizer\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 20000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 3\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: /tmp/tmpzeb988f4\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 78967 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=5053323\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9501% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=1185\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999501\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 78967 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 159138 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 78967\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 195706\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 195706 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=83228 obj=12.5937 num_tokens=378608 num_tokens/piece=4.54905\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=70410 obj=11.4417 num_tokens=379922 num_tokens/piece=5.39585\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=52802 obj=11.4471 num_tokens=396861 num_tokens/piece=7.51602\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=52784 obj=11.4136 num_tokens=397192 num_tokens/piece=7.52486\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=39588 obj=11.5538 num_tokens=420665 num_tokens/piece=10.6261\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=39588 obj=11.5172 num_tokens=420679 num_tokens/piece=10.6264\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=29691 obj=11.7107 num_tokens=446988 num_tokens/piece=15.0547\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=29691 obj=11.6693 num_tokens=446992 num_tokens/piece=15.0548\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=22268 obj=11.9067 num_tokens=473392 num_tokens/piece=21.2588\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=22268 obj=11.8609 num_tokens=473387 num_tokens/piece=21.2586\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=22000 obj=11.8792 num_tokens=474446 num_tokens/piece=21.5657\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=22000 obj=11.8767 num_tokens=474444 num_tokens/piece=21.5656\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: tk_model/ko_tokenizer.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: tk_model/ko_tokenizer.vocab\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /tmp/tmpm8o3hev1\n",
      "  input_format: \n",
      "  model_prefix: tk_model/en_tokenizer\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 20000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 3\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: /tmp/tmpm8o3hev1\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 78956 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=10661485\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9909% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=29\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999909\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 78956 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 82992 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 78956\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 44562\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 44562 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=34535 obj=9.86221 num_tokens=83351 num_tokens/piece=2.41352\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=25851 obj=8.00619 num_tokens=83809 num_tokens/piece=3.242\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=21977 obj=7.92346 num_tokens=84668 num_tokens/piece=3.85257\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=21848 obj=7.90465 num_tokens=84910 num_tokens/piece=3.8864\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: tk_model/en_tokenizer.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: tk_model/en_tokenizer.vocab\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_tokenizer(corpus,\n",
    "                        vocab_size,\n",
    "                        lang=\"ko\",\n",
    "                        pad_id=0,\n",
    "                        bos_id=1,\n",
    "                        eos_id=2,\n",
    "                        unk_id=3):\n",
    "    # 임시 파일을 사용해 SentencePiece 학습\n",
    "    with tempfile.NamedTemporaryFile(delete=False, mode='w', encoding='utf-8') as temp_file:\n",
    "        for sentence in corpus:\n",
    "            temp_file.write(sentence + \"\\n\")\n",
    "        temp_file_path = temp_file.name\n",
    "\n",
    "    # SentencePiece 모델 학습\n",
    "    spm.SentencePieceTrainer.train(\n",
    "        input=temp_file_path,\n",
    "        model_prefix=f\"tk_model/{lang}_tokenizer\",\n",
    "        vocab_size=vocab_size,\n",
    "        pad_id=pad_id,\n",
    "        bos_id=bos_id,\n",
    "        eos_id=eos_id,\n",
    "        unk_id=unk_id\n",
    "    )\n",
    "    \n",
    "    # SentencePiece 모델 로드\n",
    "    tokenizer = spm.SentencePieceProcessor()\n",
    "    tokenizer.load(f\"tk_model/{lang}_tokenizer.model\")\n",
    "\n",
    "    return tokenizer\n",
    "    \n",
    "\n",
    "SRC_VOCAB_SIZE = TGT_VOCAB_SIZE = 20000\n",
    "\n",
    "eng_corpus = []\n",
    "kor_corpus = []\n",
    "\n",
    "for pair in cleaned_corpus:\n",
    "    k, e = pair[0], pair[1]\n",
    "\n",
    "    kor_corpus.append(preprocess_sentence(k))\n",
    "    eng_corpus.append(preprocess_sentence(e))\n",
    "\n",
    "ko_tokenizer = generate_tokenizer(kor_corpus, SRC_VOCAB_SIZE, \"ko\")\n",
    "en_tokenizer = generate_tokenizer(eng_corpus, TGT_VOCAB_SIZE, \"en\")\n",
    "en_tokenizer.set_encode_extra_options(\"bos:eos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7aae0ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이날 지진의 진원지는 필리핀 북부 바탄아일랜드 바스코에서 서쪽으로 km , 대만 타이베이에서 서쪽으로 km 떨어진 지역이다 .'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kor_corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f3bb236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dae2fb409d946dc97cb0b36b89a623b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78968 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm    # Process 과정을 보기 위해\n",
    "\n",
    "src_corpus = []\n",
    "tgt_corpus = []\n",
    "\n",
    "max_length = 10\n",
    "\n",
    "assert len(kor_corpus) == len(eng_corpus)\n",
    "\n",
    "# 토큰의 길이가 50 이하인 문장만 남깁니다. \n",
    "for idx in tqdm(range(len(kor_corpus))):\n",
    "    kor_tk_corpus = ko_tokenizer.encode(kor_corpus[idx])\n",
    "    eng_tk_corpus = ko_tokenizer.encode(eng_corpus[idx])\n",
    "    \n",
    "    # 한국어만 50개 이하로 설정하면 7만개정도의 데이터, 둘다 설정하면 4만개정도가 나온다\n",
    "    if len(kor_tk_corpus) < max_length+1 and len(eng_tk_corpus) < max_length+1:\n",
    "        src_corpus.append(kor_tk_corpus)\n",
    "        tgt_corpus.append(eng_tk_corpus)\n",
    "\n",
    "# 패딩처리를 완료하여 학습용 데이터를 완성합니다. \n",
    "enc_train = tf.keras.preprocessing.sequence.pad_sequences(src_corpus, padding='post')\n",
    "dec_train = tf.keras.preprocessing.sequence.pad_sequences(tgt_corpus, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3096adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e937fa3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553f981e",
   "metadata": {},
   "source": [
    "# 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3616c12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, int(i) / d_model)\n",
    "\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "    return sinusoid_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38147947",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        self.W_q = tf.keras.layers.Dense(d_model) # Linear Layer\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "        QK = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "            \n",
    "        if mask is not None: \n",
    "            scaled_qk += (mask * -1e9)   \n",
    "\n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "\n",
    "        return out, attentions\n",
    "        \n",
    "\n",
    "    def split_heads(self, x):\n",
    "        \"\"\"\n",
    "        Embedding을 Head의 수로 분할하는 함수\n",
    "\n",
    "        x: [ batch x length x emb ]\n",
    "        return: [ batch x heads x length x self.depth ]\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        split_x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
    "\n",
    "        return split_x\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        combined_x = tf.reshape(combined_x, (batch_size, -1, self.d_model))\n",
    "        return combined_x\n",
    "\n",
    "    def call(self, Q, K, V, mask):\n",
    "        \"\"\"\n",
    "        아래 순서에 따라 소스를 작성하세요.\n",
    "\n",
    "        Step 1: Linear_in(Q, K, V) -> WQ, WK, WV\n",
    "        Step 2: Split Heads(WQ, WK, WV) -> WQ_split, WK_split, WV_split\n",
    "        Step 3: Scaled Dot Product Attention(WQ_split, WK_split, WV_split)\n",
    "                 -> out, attention_weights\n",
    "        Step 4: Combine Heads(out) -> out\n",
    "        Step 5: Linear_out(out) -> out\n",
    "\n",
    "        \"\"\"\n",
    "        WQ = self.W_q(Q)\n",
    "        WK = self.W_k(K)\n",
    "        WV = self.W_v(V)\n",
    "        \n",
    "        WQ_split = self.split_heads(WQ)\n",
    "        WK_split = self.split_heads(WK)\n",
    "        WV_split = self.split_heads(WV)\n",
    "        \n",
    "        out, attention_weights = self.scaled_dot_product_attention(WQ_split, WK_split, WV_split,mask)\n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "        return out, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c61d616",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.w_1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.w_2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.w_1(x)\n",
    "        out = self.w_2(out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a982713",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "\n",
    "        \"\"\"\n",
    "        Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "        \n",
    "        \"\"\"\n",
    "        Position-Wise Feed Forward Network\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "        \n",
    "        return out, enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e814cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecoderLayer 클래스를 작성하세요.\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x, enc_out, enc_dec_mask, padding_mask):\n",
    "        \"\"\"\n",
    "        self MHA \n",
    "        \"\"\"\n",
    "\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "        \"\"\"\n",
    "        cross MHA \n",
    "        \"\"\"\n",
    "\n",
    "        residual = out\n",
    "        out = self.norm_2(x)\n",
    "        out, enc_dec_attn = self.enc_dec_attn(out, enc_out, enc_out, enc_dec_mask)\n",
    "        print('okok')\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "        \"\"\"\n",
    "        Position-Wise Feed Forward Network\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, dec_attn, enc_dec_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18337bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                        for _ in range(n_layers)]\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "    \n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "        \n",
    "        return out, enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8f71b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                            for _ in range(n_layers)]\n",
    "                            \n",
    "                            \n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "        out = x\n",
    "    \n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = \\\n",
    "            self.dec_layers[i](out, enc_out, causality_mask, padding_mask)\n",
    "\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce9b038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 src_vocab_size,\n",
    "                 tgt_vocab_size,\n",
    "                 pos_len,\n",
    "                 dropout=0.2,\n",
    "                 shared=True):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "        \"\"\"\n",
    "        1. Embedding Layer 정의\n",
    "        2. Positional Encoding 정의\n",
    "        3. Encoder / Decoder 정의\n",
    "        4. Output Linear 정의\n",
    "        5. Shared Weights\n",
    "        6. Dropout 정의\n",
    "        \"\"\"\n",
    "        self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "        self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "\n",
    "        self.shared = shared\n",
    "\n",
    "        if shared: self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "\n",
    "    def embedding(self, emb, x):\n",
    "        \"\"\"\n",
    "        입력된 정수 배열을 Embedding + Pos Encoding\n",
    "        + Shared일 경우 Scaling 작업 포함\n",
    "\n",
    "        x: [ batch x length ]\n",
    "        return: [ batch x length x emb ]\n",
    "        \"\"\"\n",
    "        seq_len = x.shape[1]\n",
    "        out = emb(x)\n",
    "\n",
    "        if self.shared: out *= np.sqrt(self.d_model)\n",
    "\n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "        return out\n",
    "\n",
    "        \n",
    "    def call(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask):\n",
    "        \"\"\"\n",
    "        아래 순서에 따라 소스를 작성하세요.\n",
    "\n",
    "        Step 1: Embedding(enc_in, dec_in) -> enc_in, dec_in\n",
    "        Step 2: Encoder(enc_in, enc_mask) -> enc_out, enc_attns\n",
    "        Step 3: Decoder(dec_in, enc_out, mask)\n",
    "                -> dec_out, dec_attns, dec_enc_attns\n",
    "        Step 4: Out Linear(dec_out) -> logits\n",
    "        \"\"\"\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "\n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "        \n",
    "        dec_out, dec_attns, dec_enc_attns = \\\n",
    "        self.decoder(dec_in, enc_out, causality_mask, dec_mask)\n",
    "        \n",
    "        logits = self.fc(dec_out)\n",
    "        \n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27ea1b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_causality_mask(src_len, tgt_len):\n",
    "    mask = 1 - np.cumsum(np.eye(src_len, tgt_len), 0)\n",
    "    return tf.cast(mask, tf.float32)\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_mask = generate_padding_mask(tgt)\n",
    "    \n",
    "    dec_causality_mask = generate_causality_mask(tgt.shape[1], tgt.shape[1])\n",
    "    \n",
    "    dec_mask = tf.maximum(dec_mask, dec_causality_mask)\n",
    "    \n",
    "    dec_enc_mask = generate_padding_mask(tgt)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d305d486",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "learning_rate = LearningRateScheduler(512)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                     beta_1=0.9,\n",
    "                                     beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "baf11d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 2\n",
    "d_model = 512\n",
    "n_heads = 8\n",
    "d_ff= 2048\n",
    "src_vocab_size = 20000\n",
    "tgt_vocab_size= 20000\n",
    "pos_len= max_length\n",
    "dropout=0.2\n",
    "shared=True\n",
    "\n",
    "transformer =Transformer(n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 src_vocab_size,\n",
    "                 tgt_vocab_size,\n",
    "                 pos_len,\n",
    "                 dropout=0.2,\n",
    "                 shared=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9b2fa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = LearningRateScheduler(512)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                     beta_1=0.9,\n",
    "                                     beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab1cffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    # Masking 되지 않은 입력의 개수로 Scaling하는 과정\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c92fe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Step 함수 정의\n",
    "\n",
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    gold = tgt[:, 1:]\n",
    "        \n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt)\n",
    "\n",
    "    # 계산된 loss에 tf.GradientTape()를 적용해 학습을 진행합니다.\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        model(src, tgt, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions[:, :-1])\n",
    "        \n",
    "        variables = model.trainable_variables\n",
    "        gradients = tape.gradient(loss, variables)\n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b21ddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_attention(src, tgt, enc_attns, dec_attns, dec_enc_attns):\n",
    "    def draw(data, ax, x=\"auto\", y=\"auto\"):\n",
    "        import seaborn\n",
    "        seaborn.heatmap(data, \n",
    "                        square=True,\n",
    "                        vmin=0.0, vmax=1.0, \n",
    "                        cbar=False, ax=ax,\n",
    "                        xticklabels=x,\n",
    "                        yticklabels=y)\n",
    "        \n",
    "    for layer in range(0, 2, 1):\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        print(\"Encoder Layer\", layer + 1)\n",
    "        for h in range(4):\n",
    "            draw(enc_attns[layer][0, h, :len(src), :len(src)], axs[h], src, src)\n",
    "        plt.show()\n",
    "        \n",
    "    for layer in range(0, 2, 1):\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        print(\"Decoder Self Layer\", layer+1)\n",
    "        for h in range(4):\n",
    "            draw(dec_attns[layer][0, h, :len(tgt), :len(tgt)], axs[h], tgt, tgt)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Decoder Src Layer\", layer+1)\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        for h in range(4):\n",
    "            draw(dec_enc_attns[layer][0, h, :len(tgt), :len(src)], axs[h], src, tgt)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45ef36dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(sentence, model, src_tokenizer, tgt_tokenizer):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    pieces = src_tokenizer.encode_as_pieces(sentence)\n",
    "    tokens = src_tokenizer.encode_as_ids(sentence)\n",
    "\n",
    "    _input = tf.keras.preprocessing.sequence.pad_sequences([tokens],\n",
    "                                                           maxlen=enc_train.shape[-1],\n",
    "                                                           padding='post')\n",
    "    \n",
    "    ids = []\n",
    "    output = tf.expand_dims([tgt_tokenizer.bos_id()], 0)\n",
    "    for i in range(dec_train.shape[-1]):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
    "        generate_masks(_input, output)\n",
    "\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns =\\\n",
    "        model(_input, \n",
    "              output,\n",
    "              enc_padding_mask,\n",
    "              combined_mask,\n",
    "              dec_padding_mask)\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "\n",
    "        if tgt_tokenizer.eos_id() == predicted_id:\n",
    "            result = tgt_tokenizer.decode_ids(ids)\n",
    "            return pieces, result, enc_attns, dec_attns, dec_enc_attns\n",
    "\n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "\n",
    "    result = tgt_tokenizer.decode_ids(ids)\n",
    "\n",
    "    return pieces, result, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61508365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, model, src_tokenizer, tgt_tokenizer, plot_attention=False):\n",
    "    pieces, result, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "    evaluate(sentence, model, src_tokenizer, tgt_tokenizer)\n",
    "    \n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    if plot_attention:\n",
    "        visualize_attention(pieces, result.split(), enc_attns, dec_attns, dec_enc_attns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d20638cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2570/4149354440.py:20: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  t = tqdm_notebook(idx_list)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74829e5d1ac54fc4be44b88be8799449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch\n",
      "batch1\n",
      "batch1\n",
      "batch1\n",
      "batch1\n",
      "batch1\n",
      "batch1\n",
      "batch1\n",
      "batch1\n",
      "batch1\n",
      "batch1\n",
      "batch1\n",
      "batch1\n",
      "batch1\n",
      "batch1\n",
      "batch1\n",
      "batch1\n",
      "batch1\n",
      "okok\n",
      "okok\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "required broadcastable shapes [Op:AddV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2570/4149354440.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mko_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men_tokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2570/2261353251.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(sentence, model, src_tokenizer, tgt_tokenizer, plot_attention)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_attention\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpieces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_attns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_attns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_attns\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_tokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2570/2147430531.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(sentence, model, src_tokenizer, tgt_tokenizer)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_attns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_attns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_attns\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         model(_input, \n\u001b[0m\u001b[1;32m     19\u001b[0m               \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m               \u001b[0menc_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2570/2778832141.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mdec_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_attns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_attns\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcausality_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2570/3206239168.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, enc_out, causality_mask, padding_mask)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_attn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_enc_attn\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcausality_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mdec_attns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_attn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2570/2629357288.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, enc_out, enc_dec_mask, padding_mask)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_dec_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_dec_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_dec_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'okok'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2570/651275801.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, Q, K, V, mask)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mWV_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaled_dot_product_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWQ_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWK_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWV_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombine_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2570/651275801.py\u001b[0m in \u001b[0;36mscaled_dot_product_attention\u001b[0;34m(self, Q, K, V, mask)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mscaled_qk\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1e9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mattentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_qk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_same_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_add_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1698\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1700\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd_v2\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    453\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6940\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6941\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6942\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: required broadcastable shapes [Op:AddV2]"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "\n",
    "from tqdm import tqdm_notebook \n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "\n",
    "examples = [\n",
    "            \"오바마는 대통령이다.\",\n",
    "            \"시민들은 도시 속에 산다.\",\n",
    "            \"커피는 필요 없다.\",\n",
    "            \"일곱 명의 사망자가 발생했다.\"\n",
    "]\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm_notebook(idx_list)\n",
    "    print('epoch')\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        train_step(enc_train[idx:idx+BATCH_SIZE],\n",
    "                    dec_train[idx:idx+BATCH_SIZE],\n",
    "                    transformer,\n",
    "                    optimizer)\n",
    "        print('batch1')\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
    "\n",
    "    for example in examples:\n",
    "        translate(example, transformer, ko_tokenizer, en_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef3ba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Processing batch: {idx} to {idx+BATCH_SIZE}\")\n",
    "print(f\"Source batch shape: {enc_train[idx:idx+BATCH_SIZE].shape}\")\n",
    "print(f\"Target batch shape: {dec_train[idx:idx+BATCH_SIZE].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b7ea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_train[idx:idx+BATCH_SIZE].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d306f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer =Transformer(n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 src_vocab_size,\n",
    "                 tgt_vocab_size,\n",
    "                 pos_len,\n",
    "                 dropout=0.2,\n",
    "                 shared=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2ddec7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_causality_mask(src_len, tgt_len):\n",
    "    mask = 1 - np.cumsum(np.eye(src_len, tgt_len), 0)\n",
    "    return tf.cast(mask, tf.float32)\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_mask = generate_padding_mask(tgt)\n",
    "    \n",
    "    dec_causality_mask = generate_causality_mask(tgt.shape[1], tgt.shape[1])\n",
    "    \n",
    "    dec_mask = tf.maximum(dec_mask, dec_causality_mask)\n",
    "    \n",
    "    dec_enc_mask = generate_padding_mask(tgt)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask\n",
    "\n",
    "src = enc_train[idx:idx+BATCH_SIZE] # (64,10)\n",
    "tgt = dec_train[idx:idx+BATCH_SIZE] # (64,134)\n",
    "\n",
    "enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt)\n",
    "# transformer(src,tgt,enc_mask,dec_enc_mask,dec_mask)\n",
    "\n",
    "print(enc_mask.shape)\n",
    "print(dec_mask.shape)\n",
    "print(dec_enc_mask.shape)\n",
    "\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax3 = fig.add_subplot(133)\n",
    "\n",
    "ax1.set_title('1) Encoder Mask')\n",
    "ax2.set_title('2) Encoder-Decoder Mask')\n",
    "ax3.set_title('3) Decoder Mask')\n",
    "\n",
    "ax1.imshow(enc_mask[:4, 0, 0].numpy(), cmap='Dark2')\n",
    "ax2.imshow(dec_enc_mask[:4,0, 0].numpy(), cmap='Dark2')\n",
    "ax3.imshow(dec_mask[0, 0].numpy(), cmap='Dark2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de31f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa12cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_encoding = positional_encoding(150, 512)\n",
    "\n",
    "pos_encoding[np.newaxis, ...][:,:40,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658a34c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_encoding = positional_encoding(150, 512)\n",
    "dropout = tf.keras.layers.Dropout(dropout)\n",
    "shared=True\n",
    "\n",
    "def embedding(emb, x):\n",
    "    seq_len = x.shape[1]\n",
    "    out = emb(x)\n",
    "    \n",
    "    \n",
    "    if shared: \n",
    "        out *= np.sqrt(512)\n",
    "\n",
    "    out += pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "    out = dropout(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "enc_emb = tf.keras.layers.Embedding(20000, 512)\n",
    "\n",
    "\n",
    "\n",
    "enc_in = embedding(enc_emb, src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91f41ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb30081",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2104a95a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
